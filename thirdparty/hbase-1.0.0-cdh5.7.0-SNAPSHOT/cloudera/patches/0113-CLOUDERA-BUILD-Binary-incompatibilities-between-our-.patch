From 1afba471a58123fb189ad7f3e7ca1688cc6c1d35 Mon Sep 17 00:00:00 2001
From: Srikanth Srungarapu <ssrungarapu@cloudera.com>
Date: Mon, 16 Mar 2015 13:37:16 -0700
Subject: [PATCH 113/226] CLOUDERA-BUILD Binary incompatibilities between our HBase 0.98.6 and 1.0 branches --ADDENDUM

Reason: Product Requirement (Compatibility)
Author: Srikanth Srungarapu
Ref: CDH-24305
---
 .../org/apache/hadoop/hbase/HTableDescriptor.java  |   28 +++++++------------
 .../hbase/mapreduce/TableRecordReaderImpl.java     |   16 +++++++++++
 .../hbase/regionserver/wal/TestDurability.java     |    1 +
 3 files changed, 27 insertions(+), 18 deletions(-)

diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java
index 6a86e17..ed2d543 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java
@@ -621,30 +621,22 @@ public class HTableDescriptor implements WritableComparable<HTableDescriptor> {
   }
 
   /**
-   * Check if async log edits are enabled on the table.
-   *
-   * @return true if that async log flush is enabled on the table
-   * @deprecated Since 0.96 we no longer have an explicity deferred log flush/sync functionality.
-   * Use {@link #getDurability()}.
+   * This method is no longer being used in CDH5.4. Please see HBASE-10471 for more details.
+   * Retaining this so as not to break compatability with earlier CDH5.x versions.
+   * @deprecated
    */
-  public synchronized boolean isAsyncLogFlush() {
+  @Deprecated
+  public synchronized boolean isDeferredLogFlush() {
     return getDurability() == Durability.ASYNC_WAL;
   }
 
   /**
-   * This is used to allowing the log edits syncing to the file system. Everytime
-   * an edit is sent to the server it is first sync'd to the file system by the
-   * log writer. This sync is an expensive operation and thus can be deferred so
-   * that the edits are kept in memory until the background async writer-sync-notifier
-   * threads do the sync and not explicitly flushed for every edit.
-   * <p>
-   * NOTE:- This option might result in data loss if the region server crashes
-   * before these pending edits in memory are flushed onto the filesystem.
-   * </p>
-   *
-   * @param isAsyncLogFlush
+   * This method is no longer being used in CDH5.4. Please see HBASE-10471 for more details.
+   * Retaining this so as not to break compatability with earlier CDH5.x versions.
+   * @deprecated
    */
-  public synchronized void setAsyncLogFlush(final boolean isAsyncLogFlush) {
+  @Deprecated
+  public synchronized void setDeferredLogFlush(final boolean isAsyncLogFlush) {
     this.setDurability(isAsyncLogFlush ? Durability.ASYNC_WAL : DEFAULT_DURABLITY);
   }
 
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableRecordReaderImpl.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableRecordReaderImpl.java
index aeb57b7..4d7814d 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableRecordReaderImpl.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableRecordReaderImpl.java
@@ -26,6 +26,7 @@ import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.hbase.classification.InterfaceAudience;
 import org.apache.hadoop.hbase.classification.InterfaceStability;
 import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.client.Result;
 import org.apache.hadoop.hbase.client.ResultScanner;
 import org.apache.hadoop.hbase.client.Scan;
@@ -128,6 +129,21 @@ public class TableRecordReaderImpl {
   }
 
   /**
+   * Sets the HBase table.
+   *
+   * @param htable  The {@link org.apache.hadoop.hbase.client.HTable} to scan.
+   * @deprecated Use {@link #setHTable(org.apache.hadoop.hbase.client.HTable htable)} instead.
+   */
+  @Deprecated
+  public void setHTable(HTable htable) {
+    Configuration conf = htable.getConfiguration();
+    logScannerActivity = conf.getBoolean(
+        ScannerCallable.LOG_SCANNER_ACTIVITY, false);
+    logPerRowCount = conf.getInt(LOG_PER_ROW_COUNT, 100);
+    this.htable = htable;
+  }
+
+  /**
    * Sets the scan defining the actual details like columns etc.
    *
    * @param scan  The scan to set.
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestDurability.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestDurability.java
index 5219d95..0081eb1 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestDurability.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestDurability.java
@@ -216,6 +216,7 @@ public class TestDurability {
       WAL log, Durability durability)
     throws IOException {
       HTableDescriptor htd = new HTableDescriptor(TableName.valueOf(tableName));
+      htd.setDurability(durability);
       HColumnDescriptor hcd = new HColumnDescriptor(FAMILY);
       htd.addFamily(hcd);
       HRegionInfo info = new HRegionInfo(htd.getTableName(), null, null, false);
-- 
1.7.0.4

